[{"content":"bandit pip3 install bandit bandit -r project sonarqube mkdir -pv /usr/app/sonar/postgresql mkdir -pv /usr/app/sonar/data mkdir -pv /usr/app/sonar/extensions mkdir -pv /usr/app/sonar/conf chomd 777 /usr/app/sonar/postgresql chomd 777 /usr/app/sonar/data chomd 777 /usr/app/sonar/extensions chomd 777 /usr/app/sonar/conf kubectl apply -f pgo.yaml -n sonarqube kubectl apply -f sonarqube.yaml -n sonarqube sonar-scanner download: https://docs.sonarsource.com/sonarqube/latest/analyzing-source-code/scanners/sonarscanner/ export PATH=\u0026#34;$PATH:/root/sonar-scanner/bin\u0026#34; conf: sonar-project.properties start: sonar-scanner ","permalink":"https://sacredartr.github.io/posts/testing-tools/","summary":"bandit pip3 install bandit bandit -r project sonarqube mkdir -pv /usr/app/sonar/postgresql mkdir -pv /usr/app/sonar/data mkdir -pv /usr/app/sonar/extensions mkdir -pv /usr/app/sonar/conf chomd 777 /usr/app/sonar/postgresql chomd 777 /usr/app/sonar/data chomd 777 /usr/app/sonar/extensions chomd 777 /usr/app/sonar/conf kubectl apply -f pgo.yaml -n sonarqube kubectl apply -f sonarqube.yaml -n sonarqube sonar-scanner download: https://docs.sonarsource.com/sonarqube/latest/analyzing-source-code/scanners/sonarscanner/ export PATH=\u0026#34;$PATH:/root/sonar-scanner/bin\u0026#34; conf: sonar-project.properties start: sonar-scanner ","title":"Testing Tools"},{"content":"Helm Daily Tips helm deploy helm upgrade --install demo demo/ -n caas --values ./values.yaml --timeout 20m helm uninstall helm list -n caas helm uninstall demo -n caas helm debug helm dependency update helm upgrade --install demo demo/ -n caas --values ./values.yaml --timeout 20m --dry-run --debug helm package demo ","permalink":"https://sacredartr.github.io/posts/helm/","summary":"Helm Daily Tips helm deploy helm upgrade --install demo demo/ -n caas --values ./values.yaml --timeout 20m helm uninstall helm list -n caas helm uninstall demo -n caas helm debug helm dependency update helm upgrade --install demo demo/ -n caas --values ./values.yaml --timeout 20m --dry-run --debug helm package demo ","title":"helm"},{"content":"Prow Deploy prepare kubernetes cluster github organization + app + webhook user kubectl create clusterrolebinding cluster-admin-binding-\u0026#34;${USER}\u0026#34; --clusterrole=cluster-admin --user=\u0026#34;${USER}\u0026#34; secret openssl rand -hex 20 \u0026gt; /path/to/hook/secret kubectl create secret -n prow generic hmac-token --from-file=hmac=/path/to/hook/secret kubectl create secret -n prow generic github-token --from-file=cert=/path/to/github/cert --from-literal=appid=\u0026lt;\u0026lt;The ID of your app\u0026gt;\u0026gt; deploy kubectl apply -f config-yaml/prow-deploy.yaml set config edit and install app at organization add webhook at github organization/pro update update-config: kubectl -n prow create configmap config --from-file=config.yaml=config.yaml --dry-run -o yaml | kubectl -n prow replace configmap config -f - update-plugins: kubectl -n prow create configmap plugins --from-file=plugins.yaml=plugins.yaml --dry-run -o yaml | kubectl -n prow replace configmap plugins -f - update-label-config: kubectl -n test-pods create configmap label-config --from-file=labels.yaml=labels.yaml --dry-run -o yaml | kubectl -n test-pods replace configmap label-config -f - ","permalink":"https://sacredartr.github.io/posts/prow-deploy/","summary":"Prow Deploy prepare kubernetes cluster github organization + app + webhook user kubectl create clusterrolebinding cluster-admin-binding-\u0026#34;${USER}\u0026#34; --clusterrole=cluster-admin --user=\u0026#34;${USER}\u0026#34; secret openssl rand -hex 20 \u0026gt; /path/to/hook/secret kubectl create secret -n prow generic hmac-token --from-file=hmac=/path/to/hook/secret kubectl create secret -n prow generic github-token --from-file=cert=/path/to/github/cert --from-literal=appid=\u0026lt;\u0026lt;The ID of your app\u0026gt;\u0026gt; deploy kubectl apply -f config-yaml/prow-deploy.yaml set config edit and install app at organization add webhook at github organization/pro update update-config: kubectl -n prow create configmap config --from-file=config.","title":"Prow Deploy"},{"content":"Harbor Deploy prepare kubernetes cluster helm crictl harbor.tar.xz redis.tar.xz pgo.tar.xz deploy pgo-ha # ctr -n k8s.io image import all pakage cd chart # created pgo namespace kubectl create ns pgo # install pgo controller CRD helm install -n pgo pgo . # check pod kubectl -n pgo get pod NAME READY STATUS RESTARTS AGE pgo-694f6b79bc-gpw2h 1/1 Running 0 16s pgo-694f6b79bc-lw9pl 1/1 Running 0 16s pgo-upgrade-76fdb74df8-ldzcr 1/1 Running 0 16s pgo-upgrade-76fdb74df8-zqrft 1/1 Running 0 16s # install ha-postgres kubectl create ns postgres kubectl -n postgres apply -f ha-postgres.yaml # check pod kubectl -n postgres get pod NAME READY STATUS RESTARTS AGE harbor-backup-c6tq-kzxd5 0/1 Completed 0 5m26s harbor-harbor-ha-instance-8ncb-0 4/4 Running 0 6m16s harbor-harbor-ha-instance-v8np-0 4/4 Running 0 6m16s harbor-pgbouncer-58d57f45d6-82skz 2/2 Running 0 6m15s harbor-pgbouncer-58d57f45d6-rks94 2/2 Running 0 6m15s harbor-repo-host-0 2/2 Running 0 6m16s # get secret kubectl -n postgres get secret harbor-pguser-harbor -o=jsonpath=\u0026#39;{@.data.password}\u0026#39; | base64 -d # get host kubectl -n postgres get secret harbor-pguser-harbor -o=jsonpath=\u0026#39;{@.data.host}\u0026#39; | base64 -d deploy redis-ha # ctr -n k8s.io image import all pakage cd chart # create redis namespace kubectl create ns redis # install redis helm install -n redis redis . # check pod kubectl -n redis get pod NAME READY STATUS RESTARTS AGE redis-redis-ha-server-0 3/3 Running 0 25s pgo-upgrade-76fdb74df8-zqrft 1/1 Running 0 16s # domain redis+sentienl redis-redis-ha.redis.svc.cluster.local k8s-haproxy redis-redis-ha-haproxy.redis.svc.cluster.local deploy harbor-ha # ctr -n k8s.io image import all pakage cd chart # create namespace kubectl create ns harbor # install harbor helm install -n harbor harbor . # check pod kubectl -n harbor get pod NAME READY STATUS RESTARTS AGE harbor-core-6cb79d76-zcjwn 1/1 Running 0 3m44s harbor-jobservice-6b8bd7d6d9-7247v 1/1 Running 0 3m44s harbor-nginx-7756ccb484-n7vpb 1/1 Running 0 3m44s harbor-portal-57cf48cfc8-7b6tq 1/1 Running 0 10m harbor-registry-cccdf8f69-m8cws 2/2 Running 0 3m44s ","permalink":"https://sacredartr.github.io/posts/harbor-deploy/","summary":"Harbor Deploy prepare kubernetes cluster helm crictl harbor.tar.xz redis.tar.xz pgo.tar.xz deploy pgo-ha # ctr -n k8s.io image import all pakage cd chart # created pgo namespace kubectl create ns pgo # install pgo controller CRD helm install -n pgo pgo . # check pod kubectl -n pgo get pod NAME READY STATUS RESTARTS AGE pgo-694f6b79bc-gpw2h 1/1 Running 0 16s pgo-694f6b79bc-lw9pl 1/1 Running 0 16s pgo-upgrade-76fdb74df8-ldzcr 1/1 Running 0 16s pgo-upgrade-76fdb74df8-zqrft 1/1 Running 0 16s # install ha-postgres kubectl create ns postgres kubectl -n postgres apply -f ha-postgres.","title":"Harbor Deploy"},{"content":"Ceph Deploy prepare 3 centos x86 |10.0.0.1|2C|4G|50G|mount 50G disk| |10.0.0.2|2C|4G|50G|mount 50G disk| |10.0.0.3|2C|4G|50G|mount50G disk| hostnamectl set-hostname node1 hostnamectl set-hostname node2 hostnamectl set-hostname node3 cat \u0026gt;\u0026gt; /etc/hosts \u0026lt;\u0026lt;EOF 10.0.0.1 node1 10.0.0.2 node2 10.0.0.3 node3 EOF install dependent packages on 3 machine cat \u0026gt; /etc/yum.repos.d/ceph.repo \u0026lt;\u0026lt;EOF [noarch] name=Ceph noarch baseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/noarch/ enabled=1 gpgcheck=0 [x86_64] name=Ceph x86_64 baseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/x86_64/ enabled=1 gpgcheck=0 EOF systemctl disable --now firewalld setenforce 0 sed -i \u0026#39;s/^SELINUX=.*/SELINUX=disabled/\u0026#39; /etc/selinux/config yum install -y chrony epel-release wget yum-utils systemctl enable --now chronyd yum install -y openssl-devel openssl-static zlib-devel lzma tk-devel xz-devel bzip2-devel ncurses-devel gdbm-devel readline-devel sqlite-devel gcc libffi-devel lvm2 install python on 3 machine wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tgz tar -xvf Python-3.7.0.tgz mv Python-3.7.0 /usr/local \u0026amp;\u0026amp; cd /usr/local/Python-3.7.0/ ./configure make make install ln -s /usr/local/Python-3.7.0/python /usr/bin/python3 cd yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo yum makecache fast yum install docker-ce-19.03.9 -y mkdir /etc/docker echo \u0026#39;{\u0026#34;registry-mirrors\u0026#34;: [\u0026#34;http://hub-mirror.c.163.com\u0026#34;]}\u0026#39;\u0026gt;/etc/docker/daemon.json systemctl enable --now docker install ceph on node1 curl https://raw.githubusercontent.com/ceph/ceph/v15.2.1/src/cephadm/cephadm -o cephadm chmod +x cephadm ./cephadm add-repo --release octopus ./cephadm install which cephadm cephadm --help cephadm bootstrap --mon-ip 10.0.0.1 mkdir -p /etc/ceph touch /etc/ceph/ceph.conf alias ceph=\u0026#39;cephadm shell -- ceph\u0026#39; cephadm add-repo --release octopus cephadm install ceph-common ssh-copy-id -f -i /etc/ceph/ceph.pub root@node2 ssh-copy-id -f -i /etc/ceph/ceph.pub root@node3 ceph orch host add node2 10.0.0.2 ceph orch host add node3 10.0.0.3 ceph orch host ls ceph orch host label add node1 mon ceph orch host label add node2 mon ceph orch host label add node3 mon ceph orch apply mon node1 ceph orch apply mon node2 ceph orch apply mon node3 wait for 20 minutes and continue(docker ps on node2 and node3 then deploy on node1) ceph orch daemon add osd node1:/dev/sdb ceph orch daemon add osd node2:/dev/sdb ceph orch daemon add osd node3:/dev/sdb ceph orch device ls ceph -s use ceph pool on k8s ceph osd pool create kubernetes 2 2 rbd pool init kubernetes ceph auth get-or-create client.kubernetes mon \u0026#39;profile rbd\u0026#39; osd \u0026#39;profile rbd pool=kubernetes\u0026#39; mgr \u0026#39;profile rbd pool=kubernetes\u0026#39; ceph mon dump parameter description kubernetes：pool name key: pool key fsid: ceph k8s id mon: k8s monitor ip(10.0.0.1:6789) ","permalink":"https://sacredartr.github.io/posts/ceph-deploy/","summary":"Ceph Deploy prepare 3 centos x86 |10.0.0.1|2C|4G|50G|mount 50G disk| |10.0.0.2|2C|4G|50G|mount 50G disk| |10.0.0.3|2C|4G|50G|mount50G disk| hostnamectl set-hostname node1 hostnamectl set-hostname node2 hostnamectl set-hostname node3 cat \u0026gt;\u0026gt; /etc/hosts \u0026lt;\u0026lt;EOF 10.0.0.1 node1 10.0.0.2 node2 10.0.0.3 node3 EOF install dependent packages on 3 machine cat \u0026gt; /etc/yum.repos.d/ceph.repo \u0026lt;\u0026lt;EOF [noarch] name=Ceph noarch baseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/noarch/ enabled=1 gpgcheck=0 [x86_64] name=Ceph x86_64 baseurl=https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/x86_64/ enabled=1 gpgcheck=0 EOF systemctl disable --now firewalld setenforce 0 sed -i \u0026#39;s/^SELINUX=.*/SELINUX=disabled/\u0026#39; /etc/selinux/config yum install -y chrony epel-release wget yum-utils systemctl enable --now chronyd yum install -y openssl-devel openssl-static zlib-devel lzma tk-devel xz-devel bzip2-devel ncurses-devel gdbm-devel readline-devel sqlite-devel gcc libffi-devel lvm2 install python on 3 machine wget https://www.","title":"Ceph Deploy"},{"content":"Kubernetes Daily Tips containerd add proxy cat\u0026gt;\u0026gt;/etc/profile\u0026lt;\u0026lt;EOF export http_proxy=http://$IP:7890 export https_proxy=http://$IP:7890 export no_proxy=\u0026#34;localhost, 127.0.0.1\u0026#34; EOF source /etc/profile rm -rf /etc/clash/env mkdir -pv /etc/clash cat\u0026gt;/etc/clash/env\u0026lt;\u0026lt;EOF http_proxy=http://$IP:7890 https_proxy=http://$IP:7890 no_proxy=\u0026#34;localhost, 127.0.0.1\u0026#34; EOF sed -i \u0026#34;21i EnvironmentFile=/etc/clash/env\u0026#34; /etc/systemd/system/containerd.service systemctl daemon-reload systemctl restart containerd patch kubectl patch svc mariadb -n demo --type=\u0026#39;json\u0026#39; -p \u0026#39;[{\u0026#34;op\u0026#34;:\u0026#34;replace\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/type\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;NodePort\u0026#34;},{\u0026#34;op\u0026#34;:\u0026#34;add\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/ports/0/nodePort\u0026#34;,\u0026#34;value\u0026#34;:30006}]\u0026#39; kubectl patch svc rabbitmq -n demo --type=\u0026#39;json\u0026#39; -p \u0026#39;[{\u0026#34;op\u0026#34;:\u0026#34;replace\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/type\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;NodePort\u0026#34;},{\u0026#34;op\u0026#34;:\u0026#34;add\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/ports/0/nodePort\u0026#34;,\u0026#34;value\u0026#34;:30007},{\u0026#34;op\u0026#34;:\u0026#34;add\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/ports/1/nodePort\u0026#34;,\u0026#34;value\u0026#34;:30008},{\u0026#34;op\u0026#34;:\u0026#34;add\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/ports/2/nodePort\u0026#34;,\u0026#34;value\u0026#34;:30009},{\u0026#34;op\u0026#34;:\u0026#34;add\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/ports/3/nodePort\u0026#34;,\u0026#34;value\u0026#34;:30010}]\u0026#39; delete kubectl delete --all deploy -n demo kubectl delete --all statefulset -n demo kubectl delete --all pod -n demo kubectl delete --all pvc -n demo kubectl delete --all pv -n demo kubectl delete ns demo images crictl rmi docker.io/busybox:latest ctr -n k8s.io image export busybox.tar.gz docker.io/busybox:latest ctr -n k8s.io image import busybox.tar.gz ctr -n k8s.io image pull docker.io/busybox:latest nerdctl -n k8s.io save -o images.tar.gz docker.io/busybox:latest nerdctl -n k8s.io load -i images.tar.gz nerdctl -n k8s.io pull docker.io/busybox:latest namespace delete failed 1. kubect delete crd resource -n caas --force 2. kubectl edit crd resource -n caas remove finalizer 3. kubectl get namespace monitoring -o json \u0026gt; monitoring.json vi monitoring.json remove finalizer kubectl proxy curl -k -H \u0026#34;Content-Type: application/json\u0026#34; -X PUT --data-binary @monitoring.json http://127.0.0.1:8001/api/v1/namespaces/monitoring/finalize recover split-brain 1.【all node】ETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/peer.crt --key=/etc/kubernetes/pki/etcd/peer.key --endpoints=https://node1_ip:2379,https://node2_ip:2379,https://node3_ip:2379 endpoint status --write-out=json | jq find the nodes with a revision difference greater than 1000 2.【healthy node】ETCDCTL_API=3 etcdctl --endpoints=https://node_ip:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key snapshot save healthy.bak 3.【all node】mv /etc/kubernetes/manifests/* ./manifests/ 4.【all node】rm -rf /var/lib/etcd/* 5.【all node】ETCDCTL_API=3 etcdctl --name ${noden_name} --initial-cluster ${node1_name}=https://${node1_ip}:2380,${node2_name}=https://${node2_ip}:2380,${node3_name}=https://${node3_ip}:2380 --initial-cluster-token etcd-cluster-1 --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key --cacert=/etc/kubernetes/pki/etcd/ca.crt --initial-advertise-peer-urls https://${noden_ip}:2380 snapshot restore healthy.bak --data-dir /var/lib/etcd 6.【healthy node】ETCDCTL_API=3 etcdctl --endpoints=https://${node1_ip}:2379,https://${node2_ip}:2379,https://${node3_ip}:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key endpoint health check etcd health 7.【all node】mv ./manifests/* /etc/kubernetes/manifests/ local-path storageclass mkdir -pv /data/local-path-provisioner kubectl apply -f local-path.yaml ","permalink":"https://sacredartr.github.io/posts/kubernetes-daily-tips/","summary":"Kubernetes Daily Tips containerd add proxy cat\u0026gt;\u0026gt;/etc/profile\u0026lt;\u0026lt;EOF export http_proxy=http://$IP:7890 export https_proxy=http://$IP:7890 export no_proxy=\u0026#34;localhost, 127.0.0.1\u0026#34; EOF source /etc/profile rm -rf /etc/clash/env mkdir -pv /etc/clash cat\u0026gt;/etc/clash/env\u0026lt;\u0026lt;EOF http_proxy=http://$IP:7890 https_proxy=http://$IP:7890 no_proxy=\u0026#34;localhost, 127.0.0.1\u0026#34; EOF sed -i \u0026#34;21i EnvironmentFile=/etc/clash/env\u0026#34; /etc/systemd/system/containerd.service systemctl daemon-reload systemctl restart containerd patch kubectl patch svc mariadb -n demo --type=\u0026#39;json\u0026#39; -p \u0026#39;[{\u0026#34;op\u0026#34;:\u0026#34;replace\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/type\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;NodePort\u0026#34;},{\u0026#34;op\u0026#34;:\u0026#34;add\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/ports/0/nodePort\u0026#34;,\u0026#34;value\u0026#34;:30006}]\u0026#39; kubectl patch svc rabbitmq -n demo --type=\u0026#39;json\u0026#39; -p \u0026#39;[{\u0026#34;op\u0026#34;:\u0026#34;replace\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/type\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;NodePort\u0026#34;},{\u0026#34;op\u0026#34;:\u0026#34;add\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/ports/0/nodePort\u0026#34;,\u0026#34;value\u0026#34;:30007},{\u0026#34;op\u0026#34;:\u0026#34;add\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/ports/1/nodePort\u0026#34;,\u0026#34;value\u0026#34;:30008},{\u0026#34;op\u0026#34;:\u0026#34;add\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/ports/2/nodePort\u0026#34;,\u0026#34;value\u0026#34;:30009},{\u0026#34;op\u0026#34;:\u0026#34;add\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/ports/3/nodePort\u0026#34;,\u0026#34;value\u0026#34;:30010}]\u0026#39; delete kubectl delete --all deploy -n demo kubectl delete --all statefulset -n demo kubectl delete --all pod -n demo kubectl delete --all pvc -n demo kubectl delete --all pv -n demo kubectl delete ns demo images crictl rmi docker.","title":"Kubernetes Daily Tips"},{"content":"Word frequency # encoding: utf-8 import jieba import pandas as pd import datetime as dt class wordCount(): def __init__(self): self.pre_data() def pre_data(self): jieba.load_userdict(\u0026#39;./dict.txt\u0026#39;) stopwords = pd.read_table(\u0026#39;./stop.txt\u0026#39;) self.stop_list = stopwords[\u0026#34;stop_word\u0026#34;].tolist() self.stop_list.append(\u0026#34;\\n\u0026#34;) def run(self, year, month): start = dt.date(year, month, 1) if month == 6: end = dt.date(year, month, 30) else: end = dt.date(year, month, 31) sql = \u0026#34;\u0026#34;\u0026#34;select fund_id, report_date, outlook as sentence from manager_viewpoint where report_date between \u0026#39;{}\u0026#39; and \u0026#39;{}\u0026#39;\u0026#34;\u0026#34;\u0026#34;.format(dt.datetime.strftime(start, \u0026#39;%Y-%m-%d\u0026#39;), dt.datetime.strftime(end, \u0026#39;%Y-%m-%d\u0026#39;)) df = pd.DataFrame() df[\u0026#39;token\u0026#39;] = df[\u0026#39;sentence\u0026#39;].apply(lambda x: [i for i in list(jieba.cut(x)) if i not in self.stop_list]) words = [] for content in df[\u0026#39;token\u0026#39;]: words.extend(content) corpus = pd.DataFrame(words, columns=[\u0026#39;word\u0026#39;]) corpus[\u0026#39;count\u0026#39;] = 1 group = corpus.groupby(\u0026#39;word\u0026#39;)[\u0026#34;count\u0026#34;].count().sort_values(ascending=False).reset_index() group[\u0026#34;statistic_date\u0026#34;] = end print(group.tail(1)) if __name__ == \u0026#39;__main__\u0026#39;: word_count = wordCount() for year in [2021]: word_count.run(year, 6) ","permalink":"https://sacredartr.github.io/posts/nlp/","summary":"Word frequency # encoding: utf-8 import jieba import pandas as pd import datetime as dt class wordCount(): def __init__(self): self.pre_data() def pre_data(self): jieba.load_userdict(\u0026#39;./dict.txt\u0026#39;) stopwords = pd.read_table(\u0026#39;./stop.txt\u0026#39;) self.stop_list = stopwords[\u0026#34;stop_word\u0026#34;].tolist() self.stop_list.append(\u0026#34;\\n\u0026#34;) def run(self, year, month): start = dt.date(year, month, 1) if month == 6: end = dt.date(year, month, 30) else: end = dt.date(year, month, 31) sql = \u0026#34;\u0026#34;\u0026#34;select fund_id, report_date, outlook as sentence from manager_viewpoint where report_date between \u0026#39;{}\u0026#39; and \u0026#39;{}\u0026#39;\u0026#34;\u0026#34;\u0026#34;.format(dt.datetime.strftime(start, \u0026#39;%Y-%m-%d\u0026#39;), dt.","title":"NLP"},{"content":"Tools Daily Tips ASCII text art generator https://textkool.com/en/ascii-art-generator?hl=default\u0026amp;vl=default\u0026amp;font=Red%20Phoenix\u0026amp;text=Your%20text%20here%20 draw https://www.draw.io/index.html kubernetes https://kubernetes.io/ chart package https://artifacthub.io/ ","permalink":"https://sacredartr.github.io/posts/tools-daily-tips/","summary":"Tools Daily Tips ASCII text art generator https://textkool.com/en/ascii-art-generator?hl=default\u0026amp;vl=default\u0026amp;font=Red%20Phoenix\u0026amp;text=Your%20text%20here%20 draw https://www.draw.io/index.html kubernetes https://kubernetes.io/ chart package https://artifacthub.io/ ","title":"Tools Daily Tips"},{"content":"Docker Daily Tips clear all containers docker stop $(docker ps -q) \u0026amp;\u0026amp; docker rm $(docker ps -aq) docker pull:error response from daemon yum install bind-utils dig @114.114.114.114 registry-1.docker.io echo \u0026#34;54.175.43.85 registry-1.docker.io\u0026#34; \u0026gt;\u0026gt; /etc/hosts clear specified containers docker stop $(docker ps -a|grep hours|awk \u0026#39;{print $1}\u0026#39;) \u0026amp;\u0026amp; docker rm $(docker ps -a|grep hours|awk \u0026#39;{print $1}\u0026#39;) create docker https registry mkdir -p /opt/docker/registry/certs openssl req -newkey rsa:4096 -nodes -sha256 -keyout /opt/docker/registry/certs/domain.key -x509 -days 365 -out /opt/docker/registry/certs/domain.crt docker run -d --name registry2 -p 5000:5000 -v /opt/docker/registry/certs:/certs -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key registry:2 use docker https registry scp /opt/docker/registry/certs/domain.crt /etc/docker/certs.d/registry.docker.com:5000/ca.crt docker pull busybox:latest docker tag busybox registry.docker.com:5000/busybox:latest docker push registry.docker.com:5000/busybox:latest curl -X GET https://registry.docker.com:5000/v2/_catalog -k create random image FROM busybox:latest COPY test-data /test-data yum -y install buildah #!/bin bash tag=$1 for ((i=1;i\u0026lt;=100;i++)); do echo busybox:v$tag-$i dd if=/dev/random of=test-data bs=2M count=1 buildah bud --tag busybox:v$tag-$i rm -rf test-data buildah push localhost/busybox:v$tag-$i docker-daemon:busybox:v$tag-$i done docker add proxy cat\u0026gt;\u0026gt;/etc/profile\u0026lt;\u0026lt;EOF export http_proxy=http://$IP:7890 export https_proxy=http://$IP:7890 export no_proxy=\u0026#34;localhost, 127.0.0.1\u0026#34; EOF source /etc/profile rm -rf /etc/clash/env mkdir -pv /etc/clash cat\u0026gt;/etc/clash/env\u0026lt;\u0026lt;EOF http_proxy=http://$IP:7890 https_proxy=http://$IP:7890 no_proxy=\u0026#34;localhost, 127.0.0.1\u0026#34; EOF mkdir -pv /etc/systemd/system/docker.service.d rm -rf /etc/systemd/system/docker.service.d/proxy.conf cat\u0026gt;/etc/systemd/system/docker.service.d/proxy.conf\u0026lt;\u0026lt;EOF [Service] EnvironmentFile=/etc/clash/env EOF systemctl daemon-reload systemctl restart docker ","permalink":"https://sacredartr.github.io/posts/docker-daily-tips/","summary":"Docker Daily Tips clear all containers docker stop $(docker ps -q) \u0026amp;\u0026amp; docker rm $(docker ps -aq) docker pull:error response from daemon yum install bind-utils dig @114.114.114.114 registry-1.docker.io echo \u0026#34;54.175.43.85 registry-1.docker.io\u0026#34; \u0026gt;\u0026gt; /etc/hosts clear specified containers docker stop $(docker ps -a|grep hours|awk \u0026#39;{print $1}\u0026#39;) \u0026amp;\u0026amp; docker rm $(docker ps -a|grep hours|awk \u0026#39;{print $1}\u0026#39;) create docker https registry mkdir -p /opt/docker/registry/certs openssl req -newkey rsa:4096 -nodes -sha256 -keyout /opt/docker/registry/certs/domain.key -x509 -days 365 -out /opt/docker/registry/certs/domain.","title":"Docker Daily Tips"},{"content":"Git Daily Tips git subsequent commit git commit --amend git case sensitive git config core.ignorecase false git mv -f old new submodule git submodule add \u0026lt;submodule_url\u0026gt; git submodule init git submodule update git submodule update --remote ","permalink":"https://sacredartr.github.io/posts/git-daily-tips/","summary":"Git Daily Tips git subsequent commit git commit --amend git case sensitive git config core.ignorecase false git mv -f old new submodule git submodule add \u0026lt;submodule_url\u0026gt; git submodule init git submodule update git submodule update --remote ","title":"Git Daily Tips"},{"content":"Linux Daily Tips clear file cat /dev/null \u0026gt; file xargs ls ./* | xargs -i cp {} /tmp/ sed sed -i \u0026#39;s/password: .*/password: 123456/g\u0026#39; file awk cat file | awk \u0026#39;$1 ~ /th/ {print $1}\u0026#39; ignore error message unalias cp 2\u0026gt;/dev/null || true append content to file echo \u0026#39;content\u0026#39; \u0026gt;\u0026gt; file login to get token token=$(curl -X POST \u0026#34;http://$external_ip/api/v1/login\u0026#34; --header \u0026#39;Content-Type: application/json\u0026#39; --data \u0026#39;{\u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;,\u0026#34;password\u0026#34;: \u0026#34;******\u0026#34;}\u0026#39; | awk -F\u0026#34;[,:}]\u0026#34; \u0026#39;{for(i=1;i\u0026lt;=NF;i++){print $(i+1)}}\u0026#39; | tr -d \u0026#39;\u0026#34;\u0026#39; | sed -n 1p) input when executing command echo yes | sh deploy.sh append content to end of file cat\u0026gt;\u0026gt;/etc/profile\u0026lt;\u0026lt;EOF export no_proxy=\u0026#34;localhost, 127.0.0.1\u0026#34; EOF append content to anywhere in the file sed -i \u0026#34;21i EnvironmentFile=/etc/clash/env\u0026#34; /etc/systemd/system/containerd.service execute shell on ssh command ssh -i ~/.ssh/key root@${HOST_IP} \u0026#39;bash -s\u0026#39; \u0026lt;\u0026lt; \u0026#39;END\u0026#39; kubectl patch svc demo -n demo --type=\u0026#39;json\u0026#39; -p \u0026#39;[{\u0026#34;op\u0026#34;:\u0026#34;replace\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/type\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;NodePort\u0026#34;},{\u0026#34;op\u0026#34;:\u0026#34;add\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/spec/ports/0/nodePort\u0026#34;,\u0026#34;value\u0026#34;:30011}]\u0026#39; END delete matching directory find /tmp/ -maxdepth 1 -name \u0026#39;yarn*\u0026#39; | xargs rm -rf configure automatic disk mounting # find UUID blkid /dev/vdb1 vi /etc/fstab UUID=a7dd2c70-132e-446e-a0f8-41d6547445fb /data ext4 defaults 0 0 ","permalink":"https://sacredartr.github.io/posts/linux-daily-tips/","summary":"Linux Daily Tips clear file cat /dev/null \u0026gt; file xargs ls ./* | xargs -i cp {} /tmp/ sed sed -i \u0026#39;s/password: .*/password: 123456/g\u0026#39; file awk cat file | awk \u0026#39;$1 ~ /th/ {print $1}\u0026#39; ignore error message unalias cp 2\u0026gt;/dev/null || true append content to file echo \u0026#39;content\u0026#39; \u0026gt;\u0026gt; file login to get token token=$(curl -X POST \u0026#34;http://$external_ip/api/v1/login\u0026#34; --header \u0026#39;Content-Type: application/json\u0026#39; --data \u0026#39;{\u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;,\u0026#34;password\u0026#34;: \u0026#34;******\u0026#34;}\u0026#39; | awk -F\u0026#34;[,:}]\u0026#34; \u0026#39;{for(i=1;i\u0026lt;=NF;i++){print $(i+1)}}\u0026#39; | tr -d \u0026#39;\u0026#34;\u0026#39; | sed -n 1p) input when executing command echo yes | sh deploy.","title":"Linux Daily Tips"}]